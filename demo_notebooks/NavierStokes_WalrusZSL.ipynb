{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d526f06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-01-20 14:05:27--  https://huggingface.co/polymathic-ai/walrus/resolve/main/extended_config.yaml\n",
      "Resolving huggingface.co (huggingface.co)... 2600:9000:28fd:de00:17:b174:6d00:93a1, 2600:9000:28fd:800:17:b174:6d00:93a1, 2600:9000:28fd:1200:17:b174:6d00:93a1, ...\n",
      "Connecting to huggingface.co (huggingface.co)|2600:9000:28fd:de00:17:b174:6d00:93a1|:443... connected.\n",
      "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
      "Location: /api/resolve-cache/models/polymathic-ai/walrus/f8fd578e7d8a15d2e510d32d5952b9eddc37548c/extended_config.yaml?%2Fpolymathic-ai%2Fwalrus%2Fresolve%2Fmain%2Fextended_config.yaml=&etag=%223eb6c57e518c935eba9ade2e0b7a3b3381f491b6%22 [following]\n",
      "--2026-01-20 14:05:27--  https://huggingface.co/api/resolve-cache/models/polymathic-ai/walrus/f8fd578e7d8a15d2e510d32d5952b9eddc37548c/extended_config.yaml?%2Fpolymathic-ai%2Fwalrus%2Fresolve%2Fmain%2Fextended_config.yaml=&etag=%223eb6c57e518c935eba9ade2e0b7a3b3381f491b6%22\n",
      "Reusing existing connection to [huggingface.co]:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8037 (7.8K) [text/plain]\n",
      "Saving to: ‘./configs//extended_config.yaml’\n",
      "\n",
      "./configs//extended 100%[===================>]   7.85K  --.-KB/s    in 0s      \n",
      "\n",
      "2026-01-20 14:05:27 (1.50 GB/s) - ‘./configs//extended_config.yaml’ saved [8037/8037]\n",
      "\n",
      "--2026-01-20 14:05:27--  https://huggingface.co/polymathic-ai/walrus/resolve/main/walrus.pt\n",
      "Resolving huggingface.co (huggingface.co)... 2600:9000:28fd:de00:17:b174:6d00:93a1, 2600:9000:28fd:800:17:b174:6d00:93a1, 2600:9000:28fd:1200:17:b174:6d00:93a1, ...\n",
      "Connecting to huggingface.co (huggingface.co)|2600:9000:28fd:de00:17:b174:6d00:93a1|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/691f2b27e01d6f3db3e150bf/fb24df8b23d8cc37ba6511bc0ff2f01b27c8f2ad63be4f405799d1a583942cf8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20260120%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20260120T140528Z&X-Amz-Expires=3600&X-Amz-Signature=4b6e44ab7e20f2dccbdeb382531b80fbdd1ce2c2136044bfaa4f67ba4fc4403f&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27walrus.pt%3B+filename%3D%22walrus.pt%22%3B&x-id=GetObject&Expires=1768921528&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2ODkyMTUyOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OTFmMmIyN2UwMWQ2ZjNkYjNlMTUwYmYvZmIyNGRmOGIyM2Q4Y2MzN2JhNjUxMWJjMGZmMmYwMWIyN2M4ZjJhZDYzYmU0ZjQwNTc5OWQxYTU4Mzk0MmNmOCoifV19&Signature=J3q2ko22ecuDN7J36Of29fYbHOFOF02d59lctw5-Lfc%7EWGEgEtzqR67Wq2GQUVC0yd-fKWxcpXQTS6oLCRehA7vHCtydVqlhghaF9kJSqEFdUJqAdE0XuSSYsl7QOkmy6hnXxJ8cxTkejSQwggLCmLKvNWY3wghRzTWNKTmOLd%7E7RFeewCX0SV%7E0Q-%7EJK%7ErYbaDYn9PgoCBBlsRvb8aePY6rjHIu8QiJICOmxqoyA-GyGkjq1qLDDvvx2j8L45VIOzeL6wKaXPRaEbsz52rCsDpXQtaSdGoDglaCjlwfIjgfo4yR-q%7EopRSPjbeKeYZZI1kwyZA3OEVq5TrtrgpQTA__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
      "--2026-01-20 14:05:28--  https://cas-bridge.xethub.hf.co/xet-bridge-us/691f2b27e01d6f3db3e150bf/fb24df8b23d8cc37ba6511bc0ff2f01b27c8f2ad63be4f405799d1a583942cf8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20260120%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20260120T140528Z&X-Amz-Expires=3600&X-Amz-Signature=4b6e44ab7e20f2dccbdeb382531b80fbdd1ce2c2136044bfaa4f67ba4fc4403f&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27walrus.pt%3B+filename%3D%22walrus.pt%22%3B&x-id=GetObject&Expires=1768921528&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2ODkyMTUyOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OTFmMmIyN2UwMWQ2ZjNkYjNlMTUwYmYvZmIyNGRmOGIyM2Q4Y2MzN2JhNjUxMWJjMGZmMmYwMWIyN2M4ZjJhZDYzYmU0ZjQwNTc5OWQxYTU4Mzk0MmNmOCoifV19&Signature=J3q2ko22ecuDN7J36Of29fYbHOFOF02d59lctw5-Lfc%7EWGEgEtzqR67Wq2GQUVC0yd-fKWxcpXQTS6oLCRehA7vHCtydVqlhghaF9kJSqEFdUJqAdE0XuSSYsl7QOkmy6hnXxJ8cxTkejSQwggLCmLKvNWY3wghRzTWNKTmOLd%7E7RFeewCX0SV%7E0Q-%7EJK%7ErYbaDYn9PgoCBBlsRvb8aePY6rjHIu8QiJICOmxqoyA-GyGkjq1qLDDvvx2j8L45VIOzeL6wKaXPRaEbsz52rCsDpXQtaSdGoDglaCjlwfIjgfo4yR-q%7EopRSPjbeKeYZZI1kwyZA3OEVq5TrtrgpQTA__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
      "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 18.245.187.54, 18.245.187.16, 18.245.187.72, ...\n",
      "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|18.245.187.54|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5145064530 (4.8G)\n",
      "Saving to: ‘./checkpoints//walrus.pt’\n",
      "\n",
      "./checkpoints//walr   0%[                    ]   2.95M  1.96MB/s               "
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 5] Input/output error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/UKAEA/Code/Foundation_Models/walrus/.venv/lib/python3.10/site-packages/IPython/utils/_process_posix.py:156\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/UKAEA/Code/Foundation_Models/walrus/.venv/lib/python3.10/site-packages/pexpect/spawnbase.py:383\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UKAEA/Code/Foundation_Models/walrus/.venv/lib/python3.10/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/UKAEA/Code/Foundation_Models/walrus/.venv/lib/python3.10/site-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m~/Documents/UKAEA/Code/Foundation_Models/walrus/.venv/lib/python3.10/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/UKAEA/Code/Foundation_Models/walrus/.venv/lib/python3.10/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwget  https://huggingface.co/polymathic-ai/walrus/resolve/main/extended_config.yaml      -O \u001b[39m\u001b[38;5;132;01m{config_base_path}\u001b[39;00m\u001b[38;5;124m/extended_config.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Download the pretrained model weights (~4.8GB)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# This is the actual neural network parameters trained on The Well datasets\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwget  https://huggingface.co/polymathic-ai/walrus/resolve/main/walrus.pt      -O \u001b[39;49m\u001b[38;5;132;43;01m{checkpoint_base_path}\u001b[39;49;00m\u001b[38;5;124;43m/walrus.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UKAEA/Code/Foundation_Models/walrus/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py:788\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UKAEA/Code/Foundation_Models/walrus/.venv/lib/python3.10/site-packages/IPython/utils/_process_posix.py:167\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    162\u001b[0m         out_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# We need to send ^C to the process.  The ascii code for '^C' is 3\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# (the character is known as ETX for 'End of Text', see\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# curses.ascii.ETX).\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msendline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mchr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Read and print any more output the program might produce on its\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# way out.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/UKAEA/Code/Foundation_Models/walrus/.venv/lib/python3.10/site-packages/pexpect/pty_spawn.py:578\u001b[0m, in \u001b[0;36mspawn.sendline\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Wraps send(), sending string ``s`` to child process, with\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m``os.linesep`` automatically appended. Returns number of bytes\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03mwritten.  Only a limited number of bytes may be sent for each\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;124;03mline in the default terminal mode, see docstring of :meth:`send`.\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    577\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coerce_send_string(s)\n\u001b[0;32m--> 578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinesep\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UKAEA/Code/Foundation_Models/walrus/.venv/lib/python3.10/site-packages/pexpect/pty_spawn.py:569\u001b[0m, in \u001b[0;36mspawn.send\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log(s, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    568\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoder\u001b[38;5;241m.\u001b[39mencode(s, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error"
     ]
    }
   ],
   "source": [
    "## Step 1: Download Model Weights and Config\n",
    "\n",
    "import os\n",
    "\n",
    "# Create directories to store checkpoints and configs\n",
    "checkpoint_base_path = \"./checkpoints/\"\n",
    "config_base_path = \"./configs/\"\n",
    "os.makedirs(checkpoint_base_path, exist_ok=True)\n",
    "os.makedirs(config_base_path, exist_ok=True)\n",
    "\n",
    "# Download the model configuration file (YAML format)\n",
    "# This contains model architecture details, training hyperparameters, and field mappings\n",
    "!wget  https://huggingface.co/polymathic-ai/walrus/resolve/main/extended_config.yaml \\\n",
    "    -O {config_base_path}/extended_config.yaml\n",
    "\n",
    "# Download the pretrained model weights (~4.8GB)\n",
    "# This is the actual neural network parameters trained on The Well datasets\n",
    "!wget  https://huggingface.co/polymathic-ai/walrus/resolve/main/walrus.pt \\\n",
    "    -O {checkpoint_base_path}/walrus.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b96cc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Vicky/Documents/UKAEA/Code/Foundation_Models/walrus/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully!\n",
      "Model has 40 processor blocks\n",
      "Hidden dimension: 1408\n"
     ]
    }
   ],
   "source": [
    "## Load configuration and checkpoint \n",
    "import numpy as np \n",
    "import torch\n",
    "import copy\n",
    "from walrus.models import IsotropicModel\n",
    "from walrus.data.well_to_multi_transformer import ChannelsFirstWithTimeFormatter\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import DictConfig, OmegaConf, open_dict\n",
    "from walrus.utils.experiment_utils import align_checkpoint_with_field_to_index_map\n",
    "from the_well.data.datasets import WellMetadata\n",
    "from the_well.data.utils import flatten_field_names\n",
    "\n",
    "# Set paths to downloaded files\n",
    "checkpoint_path = f\"{checkpoint_base_path}/walrus.pt\"\n",
    "checkpoint_config_path = f\"{config_base_path}/extended_config.yaml\"\n",
    "\n",
    "# Load the checkpoint (model weights)\n",
    "# weights_only=True for security - only loads tensor weights, not arbitrary Python objects\n",
    "# [\"app\"][\"model\"] extracts just the model state dict from the full checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"app\"][\"model\"]\n",
    "\n",
    "# Load the configuration using OmegaConf (hierarchical config management)\n",
    "config = OmegaConf.load(checkpoint_config_path)\n",
    "\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(f\"Model has {config.model.processor_blocks} processor blocks\")\n",
    "print(f\"Hidden dimension: {config.model.hidden_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eac7c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Navier-Stokes data:\n",
      "  Horizontal velocity (u): (3, 50, 100, 100)\n",
      "  Vertical velocity (v): (3, 50, 100, 100)\n",
      "  Pressure (p): (3, 50, 100, 100)\n",
      "  Spatial grid: 100 × 100\n",
      "  Time step: 0.01\n"
     ]
    }
   ],
   "source": [
    "## Load and Convert Dataset \n",
    "def Navier_Stokes_Spectral(n_sims, data_dist):\n",
    "    \"\"\"\n",
    "    Load Navier-Stokes spectral simulation data.\n",
    "    \n",
    "    Args:\n",
    "        n_sims: Number of simulations to load\n",
    "        data_dist: 'ID' for in-distribution or 'OOD' for out-of-distribution\n",
    "    \n",
    "    Returns:\n",
    "        u: Horizontal velocity [B, Nt, Nx, Ny]\n",
    "        v: Vertical velocity [B, Nt, Nx, Ny]\n",
    "        p: Pressure [B, Nt, Nx, Ny]\n",
    "        rho: Density [B, Nt, Nx, Ny]\n",
    "        x: X-coordinates\n",
    "        y: Y-coordinates  \n",
    "        dt: Time step\n",
    "    \"\"\"\n",
    "    data_loc = '/Users/Vicky/Documents/UKAEA/Code/Uncertainty_Quantification/PDE_Residuals/Neural_PDE/Data'\n",
    "    \n",
    "    # Load appropriate dataset based on distribution\n",
    "    if data_dist == 'ID':\n",
    "        data = np.load(data_loc + '/NS_Spectral_combined.npz')\n",
    "    elif data_dist == 'OOD':\n",
    "        data = np.load(data_loc + '/NS_Spectral_combined_pitagora_OOD_nu_1e-2.npz')\n",
    "\n",
    "    # Extract fields and convert to float32\n",
    "    u = data['u'].astype(np.float32)[:n_sims]  # Horizontal velocity\n",
    "    v = data['v'].astype(np.float32)[:n_sims]  # Vertical velocity\n",
    "    p = data['p'].astype(np.float32)[:n_sims]  # Pressure\n",
    "    rho = np.ones_like(u)  # Density = 1 (constant)\n",
    "    \n",
    "    # Extract coordinates and time step\n",
    "    x = data['x']\n",
    "    y = x  # Assuming square domain\n",
    "    dt = data['dt']\n",
    "\n",
    "    return u, v, p, rho, x, y, dt\n",
    "\n",
    "# Load a small subset for demonstration\n",
    "n_sims = 3  # Number of simulations to use\n",
    "data_dist = 'ID'  # Use in-distribution data\n",
    "\n",
    "# Load the raw data\n",
    "u, v, p, rho, x_coords, y_coords, dt = Navier_Stokes_Spectral(n_sims, data_dist)\n",
    "\n",
    "print(f\"Loaded Navier-Stokes data:\")\n",
    "print(f\"  Horizontal velocity (u): {u.shape}\")\n",
    "print(f\"  Vertical velocity (v): {v.shape}\")\n",
    "print(f\"  Pressure (p): {p.shape}\")\n",
    "print(f\"  Spatial grid: {len(x_coords)} × {len(y_coords)}\")\n",
    "print(f\"  Time step: {dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f53d2ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available fields in pretrained model:\n",
      "Total fields: 67\n",
      "\n",
      "Example fields: ['closed_boundary', 'open_boundary', 'bias_correction', 'pressure', 'velocity_x', 'velocity_y', 'velocity_z', 'zeros_like_density', 'speed_of_sound', 'concentration']\n",
      "\n",
      "Added new field 'blubber' with index: 67\n"
     ]
    }
   ],
   "source": [
    "# Get the field_to_index_map from the config\n",
    "# This dictionary maps field names (strings) to integer indices used by the model's embedding layer\n",
    "field_to_index_map = config.data.field_index_map_override\n",
    "\n",
    "print(\"Available fields in pretrained model:\")\n",
    "print(f\"Total fields: {len(field_to_index_map)}\")\n",
    "print(f\"\\nExample fields: {list(field_to_index_map.keys())[:10]}\")\n",
    "\n",
    "# For our synthetic example, we'll use:\n",
    "# - velocity_x (index 4) - already in pretrained model\n",
    "# - velocity_y (index 5) - already in pretrained model\n",
    "# - density (index 28) - already in pretrained model\n",
    "# - \"blubber\" - a NEW field we're adding as an example\n",
    "\n",
    "# Create a copy and add our new field\n",
    "new_field_to_index_map = dict(field_to_index_map)\n",
    "new_field_to_index_map[\"blubber\"] = max(field_to_index_map.values()) + 1  # Assign next available index\n",
    "\n",
    "print(f\"\\nAdded new field 'blubber' with index: {new_field_to_index_map['blubber']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78994e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model architecture using Hydra's instantiate\n",
    "# n_states = total number of field types the model needs to handle\n",
    "model = instantiate(\n",
    "    config.model,\n",
    "    n_states=max(new_field_to_index_map.values()) + 1,  # +1 because indices are 0-based\n",
    ")\n",
    "\n",
    "# Align the pretrained checkpoint with our new field mapping\n",
    "# This function:\n",
    "#   - Copies weights for fields that exist in both old and new mappings\n",
    "#   - Initializes random weights for new fields (like \"blubber\")\n",
    "#   - Ensures the embedding layer has the right size\n",
    "revised_model_checkpoint = align_checkpoint_with_field_to_index_map(\n",
    "    checkpoint_state_dict=checkpoint,           # Pretrained weights\n",
    "    model_state_dict=model.state_dict(),        # Current model structure\n",
    "    checkpoint_field_to_index_map=field_to_index_map,      # Original mapping\n",
    "    model_field_to_index_map=new_field_to_index_map,       # New mapping with \"blubber\"\n",
    ")\n",
    "\n",
    "# Load the aligned weights into the model\n",
    "model.load_state_dict(revised_model_checkpoint)\n",
    "\n",
    "# Move model to GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)\n",
    "\n",
    "# Set to evaluation mode (disables dropout, batch norm training behavior, etc.)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Formatter and RevIn \n",
    "\n",
    "# Formatter handles tensor shape conversions between Well format and model format\n",
    "formatter = ChannelsFirstWithTimeFormatter()\n",
    "\n",
    "# RevIN (Reversible Instance Normalization) handles data normalization\n",
    "# instantiate() is used because config.trainer.revin is a partial function\n",
    "revin = instantiate(config.trainer.revin)()  \n",
    "\n",
    "print(\"Helper objects initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659273da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Rollout Function \n",
    "\n",
    "from walrus.trainer.training import expand_mask_to_match\n",
    "\n",
    "def rollout_model(model, revin, batch, formatter, max_rollout_steps=200, model_epsilon=1e-5, device=torch.device(\"cpu\")):\n",
    "    \"\"\"Rollout the model autoregressively for multiple timesteps.\n",
    "    \n",
    "    Args:\n",
    "        model: The Walrus model\n",
    "        revin: Reversible normalization object\n",
    "        batch: Dictionary containing input data\n",
    "        formatter: Converts between data formats\n",
    "        max_rollout_steps: Maximum timesteps to predict\n",
    "        model_epsilon: Small value for numerical stability in normalization\n",
    "        device: torch device (cuda/cpu)\n",
    "    \n",
    "    Returns:\n",
    "        y_pred_out: Model predictions [B, T, H, W, D, C]\n",
    "        y_ref: Ground truth reference [B, T, H, W, D, C]\n",
    "    \"\"\"\n",
    "    # Extract metadata (contains dataset info like spatial dims, field names, etc.)\n",
    "    metadata = batch[\"metadata\"]\n",
    "    \n",
    "    # Move all tensors to the target device (GPU/CPU)\n",
    "    # Skip metadata and boundary_conditions as they're not tensors\n",
    "    batch = {\n",
    "        k: v.to(device)\n",
    "        if k not in {\"metadata\", \"boundary_conditions\"}\n",
    "        else v\n",
    "        for k, v in batch.items()\n",
    "    }\n",
    "    \n",
    "    # Check if there's a mask field (for masked regions like obstacles)\n",
    "    # If mask exists, extract it and move to device\n",
    "    if (\n",
    "        \"mask\" in batch[\"metadata\"].constant_field_names[0]\n",
    "    ):\n",
    "        mask_index = batch[\"metadata\"].constant_field_names[0].index(\"mask\")\n",
    "        mask = batch[\"constant_fields\"][..., mask_index : mask_index + 1]\n",
    "        mask = mask.to(device, dtype=torch.bool)\n",
    "    else:\n",
    "        mask = None\n",
    "\n",
    "    # Format the input data for the model\n",
    "    # Returns:\n",
    "    #   inputs: Formatted input fields\n",
    "    #   y_ref: Reference output (ground truth) for comparison\n",
    "    inputs, y_ref = formatter.process_input(\n",
    "        batch,\n",
    "        causal_in_time=model.causal_in_time,  # Whether model uses causal masking\n",
    "        predict_delta=True,                    # Predict change (delta) rather than absolute values\n",
    "        train=False,                           # Inference mode (no training-specific augmentations)\n",
    "    )\n",
    "\n",
    "    # Calculate how many timesteps we'll predict\n",
    "    # Format: inputs is [T, B, C, H, W, D], y_ref is [B, T, H, W, D, C]\n",
    "    T_in = batch[\"input_fields\"].shape[1]  # Number of input timesteps (e.g., 6)\n",
    "    max_rollout_steps = max_rollout_steps + (T_in - 1)  # Adjust for input length\n",
    "    rollout_steps = min(y_ref.shape[1], max_rollout_steps)  # Don't exceed available reference data\n",
    "    train_rollout_limit = 1  # Only predict 1 step ahead per iteration (autoregressive)\n",
    "\n",
    "    # Trim reference to match rollout length (saves memory)\n",
    "    y_ref = y_ref[:, :rollout_steps]\n",
    "    \n",
    "    # Create a copy of batch that we'll update with predictions\n",
    "    moving_batch = copy.deepcopy(batch)\n",
    "    y_preds = []  # Store all predictions\n",
    "    \n",
    "    # Main autoregressive loop\n",
    "    for i in range(train_rollout_limit - 1, rollout_steps):\n",
    "        # Format current input window for model\n",
    "        inputs, _ = formatter.process_input(moving_batch)\n",
    "        inputs = list(inputs)  # Convert to list for easier manipulation\n",
    "        \n",
    "        # Compute normalization statistics from current input window\n",
    "        # This is done inside torch.no_grad() for efficiency\n",
    "        with torch.no_grad():\n",
    "            normalization_stats = revin.compute_stats(\n",
    "                inputs[0],      # Field data\n",
    "                metadata,       # Dataset metadata\n",
    "                epsilon=model_epsilon  # For numerical stability\n",
    "            )\n",
    "        \n",
    "        # Normalize inputs using computed statistics\n",
    "        # inputs[0] = field data, inputs[1] = constant fields, inputs[2] = boundary conditions\n",
    "        normalized_inputs = inputs[:]  # Shallow copy\n",
    "        normalized_inputs[0] = revin.normalize_stdmean(\n",
    "            normalized_inputs[0], \n",
    "            normalization_stats\n",
    "        )\n",
    "        \n",
    "        # Run model forward pass\n",
    "        # Inputs:\n",
    "        #   - normalized_inputs[0]: Normalized field data [T, B, C, H, W, D]\n",
    "        #   - normalized_inputs[1]: Constant fields\n",
    "        #   - normalized_inputs[2]: Boundary conditions\n",
    "        #   - metadata: Dataset information\n",
    "        # Output:\n",
    "        #   - y_pred: Predicted delta (change) in fields\n",
    "        y_pred = model(\n",
    "            normalized_inputs[0],\n",
    "            normalized_inputs[1],\n",
    "            normalized_inputs[2].tolist(),\n",
    "            metadata=metadata,\n",
    "        )\n",
    "        \n",
    "        # For causal models, only keep the last prediction\n",
    "        if model.causal_in_time:\n",
    "            y_pred = y_pred[-1:]  # y_pred is [T, B, C, H, W, D], take last T\n",
    "        \n",
    "        # Denormalize prediction and add to last input to get absolute value\n",
    "        # Model predicts delta (change), so: next_state = current_state + delta\n",
    "        y_pred = (inputs[0][-y_pred.shape[0]:].float()  # Get corresponding input timestep\n",
    "                  + revin.denormalize_delta(y_pred, normalization_stats))  # Add denormalized delta\n",
    "        \n",
    "        # Format output back to Well convention and trim to match reference shape\n",
    "        y_pred = formatter.process_output(y_pred, metadata)[..., : y_ref.shape[-1]]\n",
    "\n",
    "        # Apply mask if present (set masked regions to zero)\n",
    "        if mask is not None:\n",
    "            mask_pred = expand_mask_to_match(mask, y_pred)\n",
    "            y_pred.masked_fill_(mask_pred, 0)\n",
    "\n",
    "        # Zero out padded fields (fields that were added for dimensional consistency)\n",
    "        y_pred = y_pred.masked_fill(~batch[\"padded_field_mask\"], 0.0)\n",
    "\n",
    "        # Update moving window for next iteration (autoregressive step)\n",
    "        # Drop oldest timestep, append new prediction\n",
    "        if i != rollout_steps - 1:\n",
    "            moving_batch[\"input_fields\"] = torch.cat(\n",
    "                [moving_batch[\"input_fields\"][:, 1:],  # Drop first timestep\n",
    "                 y_pred[:, -1:]],                       # Append prediction\n",
    "                dim=1\n",
    "            )\n",
    "        \n",
    "        # Store prediction\n",
    "        # For causal models on first iteration, store all predictions\n",
    "        # Otherwise, store only the newest prediction\n",
    "        if model.causal_in_time and i == train_rollout_limit - 1:\n",
    "            y_preds.append(y_pred)\n",
    "        else:\n",
    "            y_preds.append(y_pred[:, -1:])\n",
    "    \n",
    "    # Concatenate all predictions along time dimension\n",
    "    y_pred_out = torch.cat(y_preds, dim=1)\n",
    "    \n",
    "    # Apply mask to reference if present\n",
    "    if mask is not None:\n",
    "        mask_ref = expand_mask_to_match(mask, y_ref)\n",
    "        y_ref.masked_fill_(mask_ref, 0)\n",
    "    \n",
    "    return y_pred_out, y_ref\n",
    "\n",
    "print(\"Rollout function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13ff66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the data ready \n",
    "\n",
    "# Define data dimensions\n",
    "B = 1       # Batch size (number of trajectories)\n",
    "T_in = 4    # Input timesteps (how many past states to condition on)\n",
    "T_out = 10  # Output timesteps (how many future states to predict)\n",
    "H = 100     # Height (spatial resolution in y direction)\n",
    "W = 100     # Width (spatial resolution in x direction)\n",
    "D = 1       # Depth (set to 1 for 2D data, would be >1 for 3D)\n",
    "C_var = 4   # Number of variable fields:\n",
    "            #   1. velocity_x (real)\n",
    "            #   2. velocity_y (real)\n",
    "            #   3. pressure  (real)\n",
    "            #   4. velocity_z (padding, needed for dimensional consistency)\n",
    "C_con = 1   # No constant (time-invariant) fields in this example\n",
    "\n",
    "# Create synthetic trajectory data\n",
    "# In practice, you would load your own data here\n",
    "synthetic_trajectory_example = {\n",
    "    # Input fields: past states that condition the prediction\n",
    "    # Shape: [batch, time_in, height, width, depth, channels]\n",
    "    \"input_fields\": torch.randn(B, T_in, H, W, D, C_var, device=device),\n",
    "    \n",
    "    # Output fields: ground truth future states (for evaluation)\n",
    "    # Shape: [batch, time_out, height, width, depth, channels]\n",
    "    \"output_fields\": torch.randn(B, T_out, H, W, D, C_var, device=device),\n",
    "    \n",
    "    # Constant fields: time-invariant quantities (e.g., geometry, material properties)\n",
    "    # Shape: [batch, height, width, depth, const_channels]\n",
    "    # Empty in this example (C_con = 0)\n",
    "    \"constant_fields\": torch.randn(B, H, W, D, C_con, device=device),\n",
    "    \n",
    "    # Boundary conditions: encodes domain boundaries\n",
    "    # Shape: [batch, 3 dimensions, 2 sides (lower/upper)]\n",
    "    # Values: 0=WALL, 1=OPEN, 2=PERIODIC\n",
    "    # [[2,2], [2,2], [2,2]] means all periodic (torus topology)\n",
    "    \"boundary_conditions\": torch.tensor([[[2, 2], [2, 2], [2, 2]] for _ in range(B)], device=device),\n",
    "    \n",
    "    # Padded field mask: indicates which fields are real vs padding\n",
    "    # True = real field, False = padding\n",
    "    # [True, True, True, True, False] means first 4 fields are real, 5th is padding\n",
    "    \"padded_field_mask\": torch.tensor([True, True, True, True, False], device=device),\n",
    "    \n",
    "    # Field indices: maps each field to its embedding index\n",
    "    # [4, 5, 28, 67, 6] means:\n",
    "    #   Field 0 → embedding 4 (velocity_x)\n",
    "    #   Field 1 → embedding 5 (velocity_y)\n",
    "    #   Field 2 → embedding 28 (density)\n",
    "    #   Field 3 → embedding 67 (blubber - our new field)\n",
    "    #   Field 4 → embedding 6 (velocity_z - padding)\n",
    "    \"field_indices\": torch.tensor([4, 5, 28, 67, 6], device=device),\n",
    "    \n",
    "    # Metadata: describes the dataset properties\n",
    "    \"metadata\": WellMetadata(\n",
    "        dataset_name=\"synthetic_dataset\",       # Name for logging/identification\n",
    "        n_spatial_dims=3,                       # 3D (even though D=1, we pad to 3D)\n",
    "        \n",
    "        # Field organization by rank:\n",
    "        # 0 = scalars (density, blubber)\n",
    "        # 1 = vectors (velocity_x, velocity_y, velocity_z)\n",
    "        # 2 = rank-2 tensors (none in this example)\n",
    "        field_names={0: ['density', \"blubber\"], 1: ['velocity_x', 'velocity_y', 'velocity_z'], 2: []},\n",
    "        \n",
    "        spatial_resolution=(128, 128, 1),       # Grid size (H, W, D)\n",
    "        scalar_names=[],                        # Global scalars (e.g., time, parameters)\n",
    "        constant_field_names={0: [], 1: [], 2: []},  # Constant fields by rank (none here)\n",
    "        constant_scalar_names=[],               # Constant global scalars\n",
    "        boundary_condition_types=[],            # Not used in this simplified example\n",
    "        n_files=[],                             # Not used\n",
    "        n_trajectories_per_file=[],             # Not used\n",
    "        n_steps_per_trajectory=[],              # Not used\n",
    "        grid_type='cartesian'                   # Coordinate system (cartesian, cylindrical, etc.)\n",
    "    ),\n",
    "}\n",
    "\n",
    "print(\"Synthetic data created!\")\n",
    "print(f\"Input shape: {synthetic_trajectory_example['input_fields'].shape}\")\n",
    "print(f\"Output shape: {synthetic_trajectory_example['output_fields'].shape}\")\n",
    "print(f\"Field indices: {synthetic_trajectory_example['field_indices']}\")\n",
    "print(f\"\\nField mapping:\")\n",
    "field_list = ['velocity_x', 'velocity_y', 'density', 'blubber', 'velocity_z (padding)']\n",
    "for i, (idx, name) in enumerate(zip(synthetic_trajectory_example['field_indices'], field_list)):\n",
    "    is_real = \"real\" if synthetic_trajectory_example['padded_field_mask'][i] else \"padding\"\n",
    "    print(f\"  Channel {i}: {name} → embedding {idx} ({is_real})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cd5d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inference \n",
    "\n",
    "# Run inference without computing gradients (faster, less memory)\n",
    "with torch.no_grad():\n",
    "    # Ensure mask is on correct device\n",
    "    synthetic_trajectory_example[\"padded_field_mask\"] = synthetic_trajectory_example[\"padded_field_mask\"].to(device)\n",
    "    \n",
    "    # Get the metadata for logging\n",
    "    fake_metadata = synthetic_trajectory_example[\"metadata\"]\n",
    "    \n",
    "    # Run the autoregressive rollout\n",
    "    # This will predict T_out (10) timesteps, one at a time\n",
    "    print(\"Running model rollout...\")\n",
    "    print(\"This performs autoregressive prediction:\")\n",
    "    print(\"  1. Use timesteps [0-5] to predict timestep [6]\")\n",
    "    print(\"  2. Use timesteps [1-6] to predict timestep [7]\")\n",
    "    print(\"  3. Continue until all 10 timesteps are predicted\")\n",
    "    print()\n",
    "    \n",
    "    y_pred, y_ref = rollout_model(\n",
    "        model,                      # The Walrus model\n",
    "        revin,                      # Normalization helper\n",
    "        synthetic_trajectory_example,  # Input data\n",
    "        formatter,                  # Data format converter\n",
    "        max_rollout_steps=200,      # Maximum steps to predict\n",
    "        device=device,              # GPU/CPU\n",
    "    )\n",
    "    \n",
    "    print(f\"Prediction complete!\")\n",
    "    print(f\"Prediction shape (with padding): {y_pred.shape}\")\n",
    "    print(f\"Reference shape (with padding): {y_ref.shape}\")\n",
    "    \n",
    "    # Remove padded fields (velocity_z) from predictions and reference\n",
    "    # Only keep the real fields (velocity_x, velocity_y, density, blubber)\n",
    "    y_pred, y_ref = (\n",
    "        y_pred[..., synthetic_trajectory_example[\"padded_field_mask\"]],\n",
    "        y_ref[..., synthetic_trajectory_example[\"padded_field_mask\"]],\n",
    "    )\n",
    "    \n",
    "    # Get human-readable field names for output\n",
    "    field_names = flatten_field_names(fake_metadata, include_constants=False)\n",
    "    used_field_names = [\n",
    "        f\n",
    "        for i, f in enumerate(field_names)\n",
    "        if synthetic_trajectory_example[\"padded_field_mask\"][i]\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nUsed fields (after removing padding): {used_field_names}\")\n",
    "    print(f\"Final prediction shape: {y_pred.shape}\")\n",
    "    print(f\"  [batch=1, time=10, height=128, width=128, depth=1, channels=4]\")\n",
    "    print(f\"\\nYou can now use y_pred for downstream analysis!\")\n",
    "    print(f\"For example:\")\n",
    "    print(f\"  - Visualize predictions: y_pred[0, :, :, :, 0, i] for field i\")\n",
    "    print(f\"  - Compute errors: (y_pred - y_ref).abs().mean()\")\n",
    "    print(f\"  - Extract single field: velocity_x = y_pred[..., 0]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
