{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "651d007e",
   "metadata": {},
   "source": [
    "# Running Walrus with Synthetic Data\n",
    "\n",
    "This notebook demonstrates how to use the Walrus foundation model with synthetic (non-Well formatted) data. This is useful when you have your own data that you want to use with Walrus without converting it to The Well format.\n",
    "\n",
    "## Prerequisites:\n",
    "- This example uses a 1.3B parameter model, so you need either enough RAM if using CPU (slow) or VRAM if using GPU\n",
    "- You'll need the Walrus checkpoint and config files (downloaded below)\n",
    "\n",
    "This notebook uses [Hydra](https://hydra.cc) to load the pretrained Walrus model and manage configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585b3797",
   "metadata": {},
   "source": [
    "## Step 1: Download Model Weights and Config\n",
    "\n",
    "First, we'll download the pretrained Walrus model weights and configuration file from HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead2153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create directories to store checkpoints and configs\n",
    "checkpoint_base_path = \"./checkpoints/\"\n",
    "config_base_path = \"./configs/\"\n",
    "os.makedirs(checkpoint_base_path, exist_ok=True)\n",
    "os.makedirs(config_base_path, exist_ok=True)\n",
    "\n",
    "# Download the model configuration file (YAML format)\n",
    "# This contains model architecture details, training hyperparameters, and field mappings\n",
    "!wget  https://huggingface.co/polymathic-ai/walrus/resolve/main/extended_config.yaml \\\n",
    "    -O {config_base_path}/extended_config.yaml\n",
    "\n",
    "# Download the pretrained model weights (~4.8GB)\n",
    "# This is the actual neural network parameters trained on The Well datasets\n",
    "!wget  https://huggingface.co/polymathic-ai/walrus/resolve/main/walrus.pt \\\n",
    "    -O {checkpoint_base_path}/walrus.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9353bb_md",
   "metadata": {},
   "source": [
    "## Step 2: Load Configuration and Checkpoint\n",
    "\n",
    "We'll load the configuration file and checkpoint. The config tells us how the model was built and trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9353bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "from walrus.models import IsotropicModel\n",
    "from walrus.data.well_to_multi_transformer import ChannelsFirstWithTimeFormatter\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import DictConfig, OmegaConf, open_dict\n",
    "from walrus.utils.experiment_utils import align_checkpoint_with_field_to_index_map\n",
    "from the_well.data.datasets import WellMetadata\n",
    "from the_well.data.utils import flatten_field_names\n",
    "\n",
    "# Set paths to downloaded files\n",
    "checkpoint_path = f\"{checkpoint_base_path}/walrus.pt\"\n",
    "checkpoint_config_path = f\"{config_base_path}/extended_config.yaml\"\n",
    "\n",
    "# Load the checkpoint (model weights)\n",
    "# weights_only=True for security - only loads tensor weights, not arbitrary Python objects\n",
    "# [\"app\"][\"model\"] extracts just the model state dict from the full checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"app\"][\"model\"]\n",
    "\n",
    "# Load the configuration using OmegaConf (hierarchical config management)\n",
    "config = OmegaConf.load(checkpoint_config_path)\n",
    "\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(f\"Model has {config.model.processor_blocks} processor blocks\")\n",
    "print(f\"Hidden dimension: {config.model.hidden_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "field_map_md",
   "metadata": {},
   "source": [
    "## Step 3: Setup Field Index Mapping\n",
    "\n",
    "The **field index map** is crucial - it tells Walrus which embedding to use for each physical field.\n",
    "\n",
    "### Why is this important?\n",
    "Walrus was pretrained on many physics domains (fluid dynamics, MHD, reaction-diffusion, etc.). Each physical field (like \"velocity_x\", \"pressure\", \"density\") has a learned embedding. When you use the model with your own data, you should map your fields to the closest pretrained embeddings when possible.\n",
    "\n",
    "### Adding new fields:\n",
    "If you have a field that wasn't in the pretraining data, you can add it as a new index. The model will initialize random embeddings for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "field_map",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the field_to_index_map from the config\n",
    "# This dictionary maps field names (strings) to integer indices used by the model's embedding layer\n",
    "field_to_index_map = config.data.field_index_map_override\n",
    "\n",
    "print(\"Available fields in pretrained model:\")\n",
    "print(f\"Total fields: {len(field_to_index_map)}\")\n",
    "print(f\"\\nExample fields: {list(field_to_index_map.keys())[:10]}\")\n",
    "\n",
    "# For our synthetic example, we'll use:\n",
    "# - velocity_x (index 4) - already in pretrained model\n",
    "# - velocity_y (index 5) - already in pretrained model\n",
    "# - density (index 28) - already in pretrained model\n",
    "# - \"blubber\" - a NEW field we're adding as an example\n",
    "\n",
    "# Create a copy and add our new field\n",
    "new_field_to_index_map = dict(field_to_index_map)\n",
    "new_field_to_index_map[\"blubber\"] = max(field_to_index_map.values()) + 1  # Assign next available index\n",
    "\n",
    "print(f\"\\nAdded new field 'blubber' with index: {new_field_to_index_map['blubber']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_init_md",
   "metadata": {},
   "source": [
    "## Step 4: Initialize and Load Model\n",
    "\n",
    "Now we'll create the model architecture and load the pretrained weights.\n",
    "\n",
    "### Key steps:\n",
    "1. **Instantiate model** with the expanded number of field embeddings\n",
    "2. **Align checkpoint** - copies pretrained weights for existing fields, initializes random weights for new fields\n",
    "3. **Load weights** into the model\n",
    "4. **Move to device** (GPU if available, otherwise CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_init",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model architecture using Hydra's instantiate\n",
    "# n_states = total number of field types the model needs to handle\n",
    "model = instantiate(\n",
    "    config.model,\n",
    "    n_states=max(new_field_to_index_map.values()) + 1,  # +1 because indices are 0-based\n",
    ")\n",
    "\n",
    "# Align the pretrained checkpoint with our new field mapping\n",
    "# This function:\n",
    "#   - Copies weights for fields that exist in both old and new mappings\n",
    "#   - Initializes random weights for new fields (like \"blubber\")\n",
    "#   - Ensures the embedding layer has the right size\n",
    "revised_model_checkpoint = align_checkpoint_with_field_to_index_map(\n",
    "    checkpoint_state_dict=checkpoint,           # Pretrained weights\n",
    "    model_state_dict=model.state_dict(),        # Current model structure\n",
    "    checkpoint_field_to_index_map=field_to_index_map,      # Original mapping\n",
    "    model_field_to_index_map=new_field_to_index_map,       # New mapping with \"blubber\"\n",
    ")\n",
    "\n",
    "# Load the aligned weights into the model\n",
    "model.load_state_dict(revised_model_checkpoint)\n",
    "\n",
    "# Move model to GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)\n",
    "\n",
    "# Set to evaluation mode (disables dropout, batch norm training behavior, etc.)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helper_md",
   "metadata": {},
   "source": [
    "## Step 5: Setup Helper Objects\n",
    "\n",
    "We need two helper objects that handle data preprocessing:\n",
    "\n",
    "### Formatter (ChannelsFirstWithTimeFormatter)\n",
    "Converts data between different tensor layouts:\n",
    "- **Input**: Well format `[B, T, H, W, D, C]` (batch, time, height, width, depth, channels)\n",
    "- **Output**: Model format `[T, B, C, H, W, D]` (time first, channels before spatial dims)\n",
    "\n",
    "### RevIN (Reversible Instance Normalization)\n",
    "Normalizes input data and denormalizes predictions:\n",
    "- Computes mean/std statistics from input data\n",
    "- Normalizes inputs before feeding to model (helps with training stability)\n",
    "- Denormalizes outputs to original scale (so predictions match input units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatter handles tensor shape conversions between Well format and model format\n",
    "formatter = ChannelsFirstWithTimeFormatter()\n",
    "\n",
    "# RevIN (Reversible Instance Normalization) handles data normalization\n",
    "# instantiate() is used because config.trainer.revin is a partial function\n",
    "revin = instantiate(config.trainer.revin)()  \n",
    "\n",
    "print(\"Helper objects initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rollout_fn_md",
   "metadata": {},
   "source": [
    "## Step 6: Define Rollout Function\n",
    "\n",
    "The rollout function performs **autoregressive prediction**:\n",
    "\n",
    "### What is autoregressive rollout?\n",
    "Instead of predicting all future timesteps at once, the model:\n",
    "1. Takes initial conditions (t=0 to t=5)\n",
    "2. Predicts next timestep (t=6)\n",
    "3. Appends prediction to inputs, drops oldest timestep\n",
    "4. Predicts next timestep (t=7)\n",
    "5. Repeats for as many steps as needed\n",
    "\n",
    "### Key operations in the loop:\n",
    "- **Format data** for model input\n",
    "- **Compute normalization stats** from current input window\n",
    "- **Normalize inputs** using RevIN\n",
    "- **Run model forward pass** to get prediction\n",
    "- **Denormalize prediction** back to original scale\n",
    "- **Update input window** with new prediction (autoregressive step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rollout_fn",
   "metadata": {},
   "outputs": [],
   "source": [
    "from walrus.trainer.training import expand_mask_to_match\n",
    "\n",
    "def rollout_model(model, revin, batch, formatter, max_rollout_steps=200, model_epsilon=1e-5, device=torch.device(\"cpu\")):\n",
    "    \"\"\"Rollout the model autoregressively for multiple timesteps.\n",
    "    \n",
    "    Args:\n",
    "        model: The Walrus model\n",
    "        revin: Reversible normalization object\n",
    "        batch: Dictionary containing input data\n",
    "        formatter: Converts between data formats\n",
    "        max_rollout_steps: Maximum timesteps to predict\n",
    "        model_epsilon: Small value for numerical stability in normalization\n",
    "        device: torch device (cuda/cpu)\n",
    "    \n",
    "    Returns:\n",
    "        y_pred_out: Model predictions [B, T, H, W, D, C]\n",
    "        y_ref: Ground truth reference [B, T, H, W, D, C]\n",
    "    \"\"\"\n",
    "    # Extract metadata (contains dataset info like spatial dims, field names, etc.)\n",
    "    metadata = batch[\"metadata\"]\n",
    "    \n",
    "    # Move all tensors to the target device (GPU/CPU)\n",
    "    # Skip metadata and boundary_conditions as they're not tensors\n",
    "    batch = {\n",
    "        k: v.to(device)\n",
    "        if k not in {\"metadata\", \"boundary_conditions\"}\n",
    "        else v\n",
    "        for k, v in batch.items()\n",
    "    }\n",
    "    \n",
    "    # Check if there's a mask field (for masked regions like obstacles)\n",
    "    # If mask exists, extract it and move to device\n",
    "    if (\n",
    "        \"mask\" in batch[\"metadata\"].constant_field_names[0]\n",
    "    ):\n",
    "        mask_index = batch[\"metadata\"].constant_field_names[0].index(\"mask\")\n",
    "        mask = batch[\"constant_fields\"][..., mask_index : mask_index + 1]\n",
    "        mask = mask.to(device, dtype=torch.bool)\n",
    "    else:\n",
    "        mask = None\n",
    "\n",
    "    # Format the input data for the model\n",
    "    # Returns:\n",
    "    #   inputs: Formatted input fields\n",
    "    #   y_ref: Reference output (ground truth) for comparison\n",
    "    inputs, y_ref = formatter.process_input(\n",
    "        batch,\n",
    "        causal_in_time=model.causal_in_time,  # Whether model uses causal masking\n",
    "        predict_delta=True,                    # Predict change (delta) rather than absolute values\n",
    "        train=False,                           # Inference mode (no training-specific augmentations)\n",
    "    )\n",
    "\n",
    "    # Calculate how many timesteps we'll predict\n",
    "    # Format: inputs is [T, B, C, H, W, D], y_ref is [B, T, H, W, D, C]\n",
    "    T_in = batch[\"input_fields\"].shape[1]  # Number of input timesteps (e.g., 6)\n",
    "    max_rollout_steps = max_rollout_steps + (T_in - 1)  # Adjust for input length\n",
    "    rollout_steps = min(y_ref.shape[1], max_rollout_steps)  # Don't exceed available reference data\n",
    "    train_rollout_limit = 1  # Only predict 1 step ahead per iteration (autoregressive)\n",
    "\n",
    "    # Trim reference to match rollout length (saves memory)\n",
    "    y_ref = y_ref[:, :rollout_steps]\n",
    "    \n",
    "    # Create a copy of batch that we'll update with predictions\n",
    "    moving_batch = copy.deepcopy(batch)\n",
    "    y_preds = []  # Store all predictions\n",
    "    \n",
    "    # Main autoregressive loop\n",
    "    for i in range(train_rollout_limit - 1, rollout_steps):\n",
    "        # Format current input window for model\n",
    "        inputs, _ = formatter.process_input(moving_batch)\n",
    "        inputs = list(inputs)  # Convert to list for easier manipulation\n",
    "        \n",
    "        # Compute normalization statistics from current input window\n",
    "        # This is done inside torch.no_grad() for efficiency\n",
    "        with torch.no_grad():\n",
    "            normalization_stats = revin.compute_stats(\n",
    "                inputs[0],      # Field data\n",
    "                metadata,       # Dataset metadata\n",
    "                epsilon=model_epsilon  # For numerical stability\n",
    "            )\n",
    "        \n",
    "        # Normalize inputs using computed statistics\n",
    "        # inputs[0] = field data, inputs[1] = constant fields, inputs[2] = boundary conditions\n",
    "        normalized_inputs = inputs[:]  # Shallow copy\n",
    "        normalized_inputs[0] = revin.normalize_stdmean(\n",
    "            normalized_inputs[0], \n",
    "            normalization_stats\n",
    "        )\n",
    "        \n",
    "        # Run model forward pass\n",
    "        # Inputs:\n",
    "        #   - normalized_inputs[0]: Normalized field data [T, B, C, H, W, D]\n",
    "        #   - normalized_inputs[1]: Constant fields\n",
    "        #   - normalized_inputs[2]: Boundary conditions\n",
    "        #   - metadata: Dataset information\n",
    "        # Output:\n",
    "        #   - y_pred: Predicted delta (change) in fields\n",
    "        y_pred = model(\n",
    "            normalized_inputs[0],\n",
    "            normalized_inputs[1],\n",
    "            normalized_inputs[2].tolist(),\n",
    "            metadata=metadata,\n",
    "        )\n",
    "        \n",
    "        # For causal models, only keep the last prediction\n",
    "        if model.causal_in_time:\n",
    "            y_pred = y_pred[-1:]  # y_pred is [T, B, C, H, W, D], take last T\n",
    "        \n",
    "        # Denormalize prediction and add to last input to get absolute value\n",
    "        # Model predicts delta (change), so: next_state = current_state + delta\n",
    "        y_pred = (inputs[0][-y_pred.shape[0]:].float()  # Get corresponding input timestep\n",
    "                  + revin.denormalize_delta(y_pred, normalization_stats))  # Add denormalized delta\n",
    "        \n",
    "        # Format output back to Well convention and trim to match reference shape\n",
    "        y_pred = formatter.process_output(y_pred, metadata)[..., : y_ref.shape[-1]]\n",
    "\n",
    "        # Apply mask if present (set masked regions to zero)\n",
    "        if mask is not None:\n",
    "            mask_pred = expand_mask_to_match(mask, y_pred)\n",
    "            y_pred.masked_fill_(mask_pred, 0)\n",
    "\n",
    "        # Zero out padded fields (fields that were added for dimensional consistency)\n",
    "        y_pred = y_pred.masked_fill(~batch[\"padded_field_mask\"], 0.0)\n",
    "\n",
    "        # Update moving window for next iteration (autoregressive step)\n",
    "        # Drop oldest timestep, append new prediction\n",
    "        if i != rollout_steps - 1:\n",
    "            moving_batch[\"input_fields\"] = torch.cat(\n",
    "                [moving_batch[\"input_fields\"][:, 1:],  # Drop first timestep\n",
    "                 y_pred[:, -1:]],                       # Append prediction\n",
    "                dim=1\n",
    "            )\n",
    "        \n",
    "        # Store prediction\n",
    "        # For causal models on first iteration, store all predictions\n",
    "        # Otherwise, store only the newest prediction\n",
    "        if model.causal_in_time and i == train_rollout_limit - 1:\n",
    "            y_preds.append(y_pred)\n",
    "        else:\n",
    "            y_preds.append(y_pred[:, -1:])\n",
    "    \n",
    "    # Concatenate all predictions along time dimension\n",
    "    y_pred_out = torch.cat(y_preds, dim=1)\n",
    "    \n",
    "    # Apply mask to reference if present\n",
    "    if mask is not None:\n",
    "        mask_ref = expand_mask_to_match(mask, y_ref)\n",
    "        y_ref.masked_fill_(mask_ref, 0)\n",
    "    \n",
    "    return y_pred_out, y_ref\n",
    "\n",
    "print(\"Rollout function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic_data_md",
   "metadata": {},
   "source": [
    "## Step 7: Create Synthetic Data\n",
    "\n",
    "Now we'll create synthetic data that matches Walrus's expected format.\n",
    "\n",
    "### Required dictionary keys:\n",
    "\n",
    "**Tensor fields:**\n",
    "- `input_fields`: Time-varying input states `[B, T_in, H, W, D, C_var]`\n",
    "- `output_fields`: Ground truth targets `[B, T_out, H, W, D, C_var]`\n",
    "- `constant_fields`: Time-invariant fields `[B, H, W, D, C_con]`\n",
    "- `boundary_conditions`: BC codes `[B, 3, 2]`\n",
    "  - Shape: [batch, dimension, (lower/upper)]\n",
    "  - Values: 0=WALL, 1=OPEN, 2=PERIODIC\n",
    "- `padded_field_mask`: Boolean mask `[C_var]`\n",
    "  - True = real field, False = padding field\n",
    "- `field_indices`: Field embedding indices `[C_var + C_con]`\n",
    "  - Maps each field to pretrained embedding index\n",
    "\n",
    "**Metadata:**\n",
    "- `metadata`: WellMetadata object with dataset information\n",
    "\n",
    "### Example for 2D velocity + scalar:\n",
    "We have velocity (2D vector) + density + blubber = 4 real fields\n",
    "But velocity needs 3D padding → add velocity_z as padding\n",
    "Total: 5 fields (4 real + 1 padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data dimensions\n",
    "B = 1       # Batch size (number of trajectories)\n",
    "T_in = 6    # Input timesteps (how many past states to condition on)\n",
    "T_out = 10  # Output timesteps (how many future states to predict)\n",
    "H = 128     # Height (spatial resolution in y direction)\n",
    "W = 128     # Width (spatial resolution in x direction)\n",
    "D = 1       # Depth (set to 1 for 2D data, would be >1 for 3D)\n",
    "C_var = 5   # Number of variable fields:\n",
    "            #   1. velocity_x (real)\n",
    "            #   2. velocity_y (real)\n",
    "            #   3. density (real)\n",
    "            #   4. blubber (real, our custom field)\n",
    "            #   5. velocity_z (padding, needed for dimensional consistency)\n",
    "C_con = 0   # No constant (time-invariant) fields in this example\n",
    "\n",
    "# Create synthetic trajectory data\n",
    "# In practice, you would load your own data here\n",
    "synthetic_trajectory_example = {\n",
    "    # Input fields: past states that condition the prediction\n",
    "    # Shape: [batch, time_in, height, width, depth, channels]\n",
    "    \"input_fields\": torch.randn(B, T_in, H, W, D, C_var, device=device),\n",
    "    \n",
    "    # Output fields: ground truth future states (for evaluation)\n",
    "    # Shape: [batch, time_out, height, width, depth, channels]\n",
    "    \"output_fields\": torch.randn(B, T_out, H, W, D, C_var, device=device),\n",
    "    \n",
    "    # Constant fields: time-invariant quantities (e.g., geometry, material properties)\n",
    "    # Shape: [batch, height, width, depth, const_channels]\n",
    "    # Empty in this example (C_con = 0)\n",
    "    \"constant_fields\": torch.randn(B, H, W, D, C_con, device=device),\n",
    "    \n",
    "    # Boundary conditions: encodes domain boundaries\n",
    "    # Shape: [batch, 3 dimensions, 2 sides (lower/upper)]\n",
    "    # Values: 0=WALL, 1=OPEN, 2=PERIODIC\n",
    "    # [[2,2], [2,2], [2,2]] means all periodic (torus topology)\n",
    "    \"boundary_conditions\": torch.tensor([[[2, 2], [2, 2], [2, 2]] for _ in range(B)], device=device),\n",
    "    \n",
    "    # Padded field mask: indicates which fields are real vs padding\n",
    "    # True = real field, False = padding\n",
    "    # [True, True, True, True, False] means first 4 fields are real, 5th is padding\n",
    "    \"padded_field_mask\": torch.tensor([True, True, True, True, False], device=device),\n",
    "    \n",
    "    # Field indices: maps each field to its embedding index\n",
    "    # [4, 5, 28, 67, 6] means:\n",
    "    #   Field 0 → embedding 4 (velocity_x)\n",
    "    #   Field 1 → embedding 5 (velocity_y)\n",
    "    #   Field 2 → embedding 28 (density)\n",
    "    #   Field 3 → embedding 67 (blubber - our new field)\n",
    "    #   Field 4 → embedding 6 (velocity_z - padding)\n",
    "    \"field_indices\": torch.tensor([4, 5, 28, 67, 6], device=device),\n",
    "    \n",
    "    # Metadata: describes the dataset properties\n",
    "    \"metadata\": WellMetadata(\n",
    "        dataset_name=\"synthetic_dataset\",       # Name for logging/identification\n",
    "        n_spatial_dims=3,                       # 3D (even though D=1, we pad to 3D)\n",
    "        \n",
    "        # Field organization by rank:\n",
    "        # 0 = scalars (density, blubber)\n",
    "        # 1 = vectors (velocity_x, velocity_y, velocity_z)\n",
    "        # 2 = rank-2 tensors (none in this example)\n",
    "        field_names={0: ['density', \"blubber\"], 1: ['velocity_x', 'velocity_y', 'velocity_z'], 2: []},\n",
    "        \n",
    "        spatial_resolution=(128, 128, 1),       # Grid size (H, W, D)\n",
    "        scalar_names=[],                        # Global scalars (e.g., time, parameters)\n",
    "        constant_field_names={0: [], 1: [], 2: []},  # Constant fields by rank (none here)\n",
    "        constant_scalar_names=[],               # Constant global scalars\n",
    "        boundary_condition_types=[],            # Not used in this simplified example\n",
    "        n_files=[],                             # Not used\n",
    "        n_trajectories_per_file=[],             # Not used\n",
    "        n_steps_per_trajectory=[],              # Not used\n",
    "        grid_type='cartesian'                   # Coordinate system (cartesian, cylindrical, etc.)\n",
    "    ),\n",
    "}\n",
    "\n",
    "print(\"Synthetic data created!\")\n",
    "print(f\"Input shape: {synthetic_trajectory_example['input_fields'].shape}\")\n",
    "print(f\"Output shape: {synthetic_trajectory_example['output_fields'].shape}\")\n",
    "print(f\"Field indices: {synthetic_trajectory_example['field_indices']}\")\n",
    "print(f\"\\nField mapping:\")\n",
    "field_list = ['velocity_x', 'velocity_y', 'density', 'blubber', 'velocity_z (padding)']\n",
    "for i, (idx, name) in enumerate(zip(synthetic_trajectory_example['field_indices'], field_list)):\n",
    "    is_real = \"real\" if synthetic_trajectory_example['padded_field_mask'][i] else \"padding\"\n",
    "    print(f\"  Channel {i}: {name} → embedding {idx} ({is_real})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run_model_md",
   "metadata": {},
   "source": [
    "## Step 8: Run Model Inference\n",
    "\n",
    "Now we'll use the model to make predictions on our synthetic data!\n",
    "\n",
    "### What happens here:\n",
    "1. Move padded field mask to device\n",
    "2. Call rollout function (autoregressive prediction loop)\n",
    "3. Remove padded fields from output (velocity_z)\n",
    "4. Extract field names for logging\n",
    "\n",
    "The model will predict 10 future timesteps based on the 6 input timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference without computing gradients (faster, less memory)\n",
    "with torch.no_grad():\n",
    "    # Ensure mask is on correct device\n",
    "    synthetic_trajectory_example[\"padded_field_mask\"] = synthetic_trajectory_example[\"padded_field_mask\"].to(device)\n",
    "    \n",
    "    # Get the metadata for logging\n",
    "    fake_metadata = synthetic_trajectory_example[\"metadata\"]\n",
    "    \n",
    "    # Run the autoregressive rollout\n",
    "    # This will predict T_out (10) timesteps, one at a time\n",
    "    print(\"Running model rollout...\")\n",
    "    print(\"This performs autoregressive prediction:\")\n",
    "    print(\"  1. Use timesteps [0-5] to predict timestep [6]\")\n",
    "    print(\"  2. Use timesteps [1-6] to predict timestep [7]\")\n",
    "    print(\"  3. Continue until all 10 timesteps are predicted\")\n",
    "    print()\n",
    "    \n",
    "    y_pred, y_ref = rollout_model(\n",
    "        model,                      # The Walrus model\n",
    "        revin,                      # Normalization helper\n",
    "        synthetic_trajectory_example,  # Input data\n",
    "        formatter,                  # Data format converter\n",
    "        max_rollout_steps=200,      # Maximum steps to predict\n",
    "        device=device,              # GPU/CPU\n",
    "    )\n",
    "    \n",
    "    print(f\"Prediction complete!\")\n",
    "    print(f\"Prediction shape (with padding): {y_pred.shape}\")\n",
    "    print(f\"Reference shape (with padding): {y_ref.shape}\")\n",
    "    \n",
    "    # Remove padded fields (velocity_z) from predictions and reference\n",
    "    # Only keep the real fields (velocity_x, velocity_y, density, blubber)\n",
    "    y_pred, y_ref = (\n",
    "        y_pred[..., synthetic_trajectory_example[\"padded_field_mask\"]],\n",
    "        y_ref[..., synthetic_trajectory_example[\"padded_field_mask\"]],\n",
    "    )\n",
    "    \n",
    "    # Get human-readable field names for output\n",
    "    field_names = flatten_field_names(fake_metadata, include_constants=False)\n",
    "    used_field_names = [\n",
    "        f\n",
    "        for i, f in enumerate(field_names)\n",
    "        if synthetic_trajectory_example[\"padded_field_mask\"][i]\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nUsed fields (after removing padding): {used_field_names}\")\n",
    "    print(f\"Final prediction shape: {y_pred.shape}\")\n",
    "    print(f\"  [batch=1, time=10, height=128, width=128, depth=1, channels=4]\")\n",
    "    print(f\"\\nYou can now use y_pred for downstream analysis!\")\n",
    "    print(f\"For example:\")\n",
    "    print(f\"  - Visualize predictions: y_pred[0, :, :, :, 0, i] for field i\")\n",
    "    print(f\"  - Compute errors: (y_pred - y_ref).abs().mean()\")\n",
    "    print(f\"  - Extract single field: velocity_x = y_pred[..., 0]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_md",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've successfully used Walrus with synthetic data without needing The Well dataset. \n",
    "\n",
    "### Key Points:\n",
    "\n",
    "1. **Field Index Mapping**: You can add new fields to the pretrained model by extending the `field_to_index_map`. Use pretrained embeddings when possible for better performance.\n",
    "\n",
    "2. **Data Format**: Walrus expects data in a specific dictionary format:\n",
    "   - Tensor shape: `[B, T, H, W, D, C]`\n",
    "   - Must include: input_fields, output_fields, boundary_conditions, field_indices, padded_field_mask, metadata\n",
    "\n",
    "3. **Padding**: For 2D data with vector fields:\n",
    "   - Velocity has 2 components (x, y) but needs 3 (x, y, z)\n",
    "   - Add velocity_z as padding, mark it False in padded_field_mask\n",
    "   - This ensures dimensional consistency across different problems\n",
    "\n",
    "4. **Metadata**: The WellMetadata object organizes fields by rank:\n",
    "   - Rank 0: scalars (density, pressure, temperature, etc.)\n",
    "   - Rank 1: vectors (velocity, magnetic field, etc.)\n",
    "   - Rank 2: tensors (stress, strain, etc.)\n",
    "\n",
    "5. **Autoregressive Prediction**: The model predicts one step at a time:\n",
    "   - Uses sliding window of past states\n",
    "   - Each prediction becomes part of next input\n",
    "   - Can accumulate errors over long rollouts\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "To use Walrus with your own data:\n",
    "\n",
    "1. **Load your data** into the required dictionary format\n",
    "   - Convert to shape `[B, T, H, W, D, C]`\n",
    "   - Ensure proper units and normalization\n",
    "\n",
    "2. **Map your fields** to pretrained embeddings when possible\n",
    "   - Check `field_to_index_map` for available fields\n",
    "   - Add new indices for novel fields\n",
    "\n",
    "3. **Set boundary conditions** appropriately\n",
    "   - 0 = WALL (Dirichlet), 1 = OPEN (outflow), 2 = PERIODIC\n",
    "\n",
    "4. **Create metadata** describing your dataset\n",
    "   - Organize fields by rank\n",
    "   - Specify spatial dimensions and grid type\n",
    "\n",
    "5. **Run predictions** using the rollout function\n",
    "   - Adjust `max_rollout_steps` as needed\n",
    "   - Monitor memory usage for large grids\n",
    "\n",
    "### Adapting to your domain:\n",
    "\n",
    "Walrus was pretrained on diverse physics problems. For best results:\n",
    "- **Use similar fields**: If your problem has velocity/pressure/density, use those embeddings\n",
    "- **Match spatial structure**: The model works best on similar grid sizes (64-256)\n",
    "- **Consider fine-tuning**: For very different domains, fine-tune on your data\n",
    "- **Check units**: Ensure your data is in reasonable numerical ranges (not too large/small)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
